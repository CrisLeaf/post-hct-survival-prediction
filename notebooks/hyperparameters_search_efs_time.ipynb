{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cris/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('muted')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/equity-post-HCT-survival-predictions/'\n",
    "RANDOM_STATE = 54321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n",
    "test_df = pd.read_csv(DATA_PATH + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(DATA_PATH + 'train_test_split/X_25-12-2024.pkl')\n",
    "y = pd.read_pickle(DATA_PATH + 'train_test_split/y_25-12-2024.pkl')\n",
    "efs_time = pd.read_pickle(DATA_PATH + 'train_test_split/efs_time_25-12-2024.pkl')\n",
    "race_group = pd.read_pickle(DATA_PATH + 'train_test_split/race_group_25-12-2024.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800, 81) (28800,) (28800,) (28800,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape, efs_time.shape, race_group.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_efs_time(model, X, efs_time, cv=10, scale=False):\n",
    "    cv_scores = []\n",
    "\n",
    "    for i in range(cv):\n",
    "        test_idxs = list(range(int((len(X)*(i)/cv)), int((len(X)*(i+1)/cv))))\n",
    "        \n",
    "        X_train = X.drop(index=test_idxs)\n",
    "        y_train = efs_time.drop(index=test_idxs)\n",
    "        \n",
    "        X_test = X.iloc[test_idxs]\n",
    "        y_test = efs_time.iloc[test_idxs]\n",
    "        \n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        \n",
    "        model_copy = clone(model)\n",
    "        \n",
    "        model_copy.fit(X_train, y_train)\n",
    "        y_pred = model_copy.predict(X_test)\n",
    "        \n",
    "        cv_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 16.8865\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor(random_state=RANDOM_STATE, verbose=-1)\n",
    "cv_score = cross_validate_efs_time(model, X, efs_time, cv=5)\n",
    "\n",
    "print(f'CV Score: {cv_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 20, 150)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 50)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 0.5, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 2000)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 5, 100)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True)\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        num_leaves=num_leaves,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        min_child_samples=min_child_samples,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    cv_score = cross_validate_efs_time(model, X, efs_time, cv=5)\n",
    "\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:11:51,394] A new study created in memory with name: no-name-e5dc54fd-3f1d-4445-ac0e-3ab93ca4af17\n",
      "[I 2025-01-12 10:12:07,122] Trial 0 finished with value: 16.7084047098786 and parameters: {'num_leaves': 50, 'max_depth': 16, 'learning_rate': 0.05129167200639864, 'n_estimators': 442, 'min_child_samples': 44, 'subsample': 0.7335527845064131, 'colsample_bytree': 0.5630653716876615, 'reg_alpha': 2.187340888115115, 'reg_lambda': 0.0015006112611769082}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:12:36,704] Trial 1 finished with value: 17.236936453389088 and parameters: {'num_leaves': 143, 'max_depth': 13, 'learning_rate': 0.11289912370842253, 'n_estimators': 551, 'min_child_samples': 82, 'subsample': 0.7091357291807747, 'colsample_bytree': 0.9352471946269185, 'reg_alpha': 0.003978384044123794, 'reg_lambda': 0.37481816249401156}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:12:59,754] Trial 2 finished with value: 17.342467847511706 and parameters: {'num_leaves': 78, 'max_depth': 38, 'learning_rate': 0.005150936532844539, 'n_estimators': 479, 'min_child_samples': 86, 'subsample': 0.9965754561669593, 'colsample_bytree': 0.6992063908454171, 'reg_alpha': 2.9312733311278714e-05, 'reg_lambda': 3.267041919086384e-06}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:14:40,504] Trial 3 finished with value: 18.59785081282818 and parameters: {'num_leaves': 111, 'max_depth': 10, 'learning_rate': 0.37947535383464587, 'n_estimators': 1700, 'min_child_samples': 23, 'subsample': 0.5402439958161394, 'colsample_bytree': 0.5945523339872842, 'reg_alpha': 0.005291508960278547, 'reg_lambda': 0.002770709243279313}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:16:04,214] Trial 4 finished with value: 18.807853168710718 and parameters: {'num_leaves': 93, 'max_depth': 21, 'learning_rate': 0.0002102007933800043, 'n_estimators': 1348, 'min_child_samples': 16, 'subsample': 0.5554576613870019, 'colsample_bytree': 0.618121529882247, 'reg_alpha': 0.00319727692695974, 'reg_lambda': 0.10551980735690003}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:16:05,258] Trial 5 finished with value: 17.202326728022836 and parameters: {'num_leaves': 27, 'max_depth': 2, 'learning_rate': 0.1391797001163938, 'n_estimators': 149, 'min_child_samples': 85, 'subsample': 0.989136807233626, 'colsample_bytree': 0.5494921137136247, 'reg_alpha': 1.799064160269924e-07, 'reg_lambda': 1.9781060811445764e-08}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:16:25,307] Trial 6 finished with value: 16.716088552093208 and parameters: {'num_leaves': 45, 'max_depth': 12, 'learning_rate': 0.018346901614255697, 'n_estimators': 711, 'min_child_samples': 85, 'subsample': 0.5101660565624575, 'colsample_bytree': 0.7577307772244029, 'reg_alpha': 3.9414015395714197e-07, 'reg_lambda': 0.046120656643325174}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:18:12,778] Trial 7 finished with value: 16.970811869982697 and parameters: {'num_leaves': 142, 'max_depth': 28, 'learning_rate': 0.004554921682377242, 'n_estimators': 1114, 'min_child_samples': 10, 'subsample': 0.705122235390125, 'colsample_bytree': 0.5510011828742725, 'reg_alpha': 0.03170740410534394, 'reg_lambda': 4.7608851744288475e-08}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:19:51,404] Trial 8 finished with value: 18.01073536302298 and parameters: {'num_leaves': 107, 'max_depth': 25, 'learning_rate': 0.0007130109714619506, 'n_estimators': 1461, 'min_child_samples': 8, 'subsample': 0.9472461070069886, 'colsample_bytree': 0.7612966453353495, 'reg_alpha': 0.9604942723429117, 'reg_lambda': 1.7502458140434138e-07}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:20:53,121] Trial 9 finished with value: 17.838247425446113 and parameters: {'num_leaves': 75, 'max_depth': 19, 'learning_rate': 0.0009750464702277818, 'n_estimators': 1318, 'min_child_samples': 68, 'subsample': 0.7201974764673943, 'colsample_bytree': 0.8740980422221407, 'reg_alpha': 0.005119005950466585, 'reg_lambda': 1.1516229841392214e-05}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:20:59,019] Trial 10 finished with value: 17.224798823735092 and parameters: {'num_leaves': 53, 'max_depth': 50, 'learning_rate': 0.02630989757680864, 'n_estimators': 135, 'min_child_samples': 41, 'subsample': 0.8493427661467882, 'colsample_bytree': 0.503853652071215, 'reg_alpha': 5.578719912383205, 'reg_lambda': 0.00011333370655279284}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:21:11,211] Trial 11 finished with value: 16.72349222585137 and parameters: {'num_leaves': 29, 'max_depth': 6, 'learning_rate': 0.027033487267329008, 'n_estimators': 747, 'min_child_samples': 58, 'subsample': 0.6177530100230683, 'colsample_bytree': 0.7736282413493969, 'reg_alpha': 1.1328379390574757e-08, 'reg_lambda': 0.005314662185343478}. Best is trial 0 with value: 16.7084047098786.\n",
      "[I 2025-01-12 10:21:38,292] Trial 12 finished with value: 16.689880483314617 and parameters: {'num_leaves': 52, 'max_depth': 15, 'learning_rate': 0.022768574353518447, 'n_estimators': 831, 'min_child_samples': 34, 'subsample': 0.8454682754109785, 'colsample_bytree': 0.670877247064319, 'reg_alpha': 1.4351541223785886e-05, 'reg_lambda': 6.448321876270641}. Best is trial 12 with value: 16.689880483314617.\n",
      "[I 2025-01-12 10:22:10,287] Trial 13 finished with value: 16.853754367460123 and parameters: {'num_leaves': 59, 'max_depth': 32, 'learning_rate': 0.06937058196008865, 'n_estimators': 915, 'min_child_samples': 33, 'subsample': 0.8561709379349901, 'colsample_bytree': 0.6552451166659621, 'reg_alpha': 3.48349132240514e-05, 'reg_lambda': 3.8099637972109917}. Best is trial 12 with value: 16.689880483314617.\n",
      "[I 2025-01-12 10:22:27,431] Trial 14 finished with value: 17.040915741406167 and parameters: {'num_leaves': 62, 'max_depth': 17, 'learning_rate': 0.011183530426048855, 'n_estimators': 423, 'min_child_samples': 41, 'subsample': 0.808701040573216, 'colsample_bytree': 0.6826184109480188, 'reg_alpha': 3.5805516972009215e-05, 'reg_lambda': 8.09205712426004}. Best is trial 12 with value: 16.689880483314617.\n",
      "[I 2025-01-12 10:22:49,951] Trial 15 finished with value: 19.09148063246637 and parameters: {'num_leaves': 40, 'max_depth': 37, 'learning_rate': 0.4860425565098263, 'n_estimators': 965, 'min_child_samples': 52, 'subsample': 0.7882893049478867, 'colsample_bytree': 0.8481034318521167, 'reg_alpha': 0.2361386350150778, 'reg_lambda': 0.00018605910082560663}. Best is trial 12 with value: 16.689880483314617.\n",
      "[I 2025-01-12 10:23:05,466] Trial 16 finished with value: 18.170640623594057 and parameters: {'num_leaves': 69, 'max_depth': 24, 'learning_rate': 0.002744533031832714, 'n_estimators': 322, 'min_child_samples': 27, 'subsample': 0.9010281068423072, 'colsample_bytree': 0.6140205558020875, 'reg_alpha': 4.955724161724077e-06, 'reg_lambda': 0.005079941805450327}. Best is trial 12 with value: 16.689880483314617.\n",
      "[I 2025-01-12 10:23:19,679] Trial 17 finished with value: 16.7168540233939 and parameters: {'num_leaves': 20, 'max_depth': 16, 'learning_rate': 0.057212947288418636, 'n_estimators': 742, 'min_child_samples': 53, 'subsample': 0.6540140084191421, 'colsample_bytree': 0.5097519980866754, 'reg_alpha': 0.00012714053559687792, 'reg_lambda': 0.45289295663164475}. Best is trial 12 with value: 16.689880483314617.\n",
      "[I 2025-01-12 10:23:49,429] Trial 18 finished with value: 17.893210916382465 and parameters: {'num_leaves': 95, 'max_depth': 7, 'learning_rate': 0.20585175823238328, 'n_estimators': 1181, 'min_child_samples': 41, 'subsample': 0.7839023769973024, 'colsample_bytree': 0.9984022862638593, 'reg_alpha': 6.932777580274567e-07, 'reg_lambda': 6.079848986380429e-06}. Best is trial 12 with value: 16.689880483314617.\n",
      "[I 2025-01-12 10:23:55,955] Trial 19 finished with value: 16.82798240692526 and parameters: {'num_leaves': 42, 'max_depth': 2, 'learning_rate': 0.04388804140348276, 'n_estimators': 1769, 'min_child_samples': 70, 'subsample': 0.6443470010274098, 'colsample_bytree': 0.7153551493687464, 'reg_alpha': 7.925405602878636, 'reg_lambda': 0.001277486697598417}. Best is trial 12 with value: 16.689880483314617.\n",
      "[I 2025-01-12 10:24:57,424] Trial 20 finished with value: 16.645564336517356 and parameters: {'num_leaves': 51, 'max_depth': 31, 'learning_rate': 0.01179204568282161, 'n_estimators': 1977, 'min_child_samples': 97, 'subsample': 0.8662660283517414, 'colsample_bytree': 0.8184788809594468, 'reg_alpha': 0.0003399220290817596, 'reg_lambda': 0.03475548829346672}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:26:00,781] Trial 21 finished with value: 16.6490797675264 and parameters: {'num_leaves': 52, 'max_depth': 31, 'learning_rate': 0.011290753119886546, 'n_estimators': 1993, 'min_child_samples': 99, 'subsample': 0.8893310685928032, 'colsample_bytree': 0.8272799435865336, 'reg_alpha': 0.0003024321552861924, 'reg_lambda': 0.03290885748244906}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:26:46,177] Trial 22 finished with value: 16.691304920694144 and parameters: {'num_leaves': 35, 'max_depth': 33, 'learning_rate': 0.009153621291931393, 'n_estimators': 1995, 'min_child_samples': 100, 'subsample': 0.8951114468498002, 'colsample_bytree': 0.8183404227225808, 'reg_alpha': 0.00043636460272524917, 'reg_lambda': 1.3545975930379652}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:27:58,134] Trial 23 finished with value: 16.912460061530428 and parameters: {'num_leaves': 60, 'max_depth': 44, 'learning_rate': 0.0028571007930757652, 'n_estimators': 1897, 'min_child_samples': 100, 'subsample': 0.9078521696748159, 'colsample_bytree': 0.8060148626017507, 'reg_alpha': 3.1987483155024e-06, 'reg_lambda': 0.08248819123762301}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:29:15,833] Trial 24 finished with value: 16.683314596241125 and parameters: {'num_leaves': 84, 'max_depth': 30, 'learning_rate': 0.013501383132992203, 'n_estimators': 1593, 'min_child_samples': 93, 'subsample': 0.8608248289233891, 'colsample_bytree': 0.8955678561824808, 'reg_alpha': 0.00017288590321925016, 'reg_lambda': 0.022548303111611174}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:30:41,574] Trial 25 finished with value: 17.40455257084749 and parameters: {'num_leaves': 88, 'max_depth': 30, 'learning_rate': 0.0013451594690980667, 'n_estimators': 1623, 'min_child_samples': 93, 'subsample': 0.9484667096741295, 'colsample_bytree': 0.8884968930267675, 'reg_alpha': 0.0003905086194163753, 'reg_lambda': 0.012954159193545188}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:32:54,840] Trial 26 finished with value: 16.74678550433841 and parameters: {'num_leaves': 127, 'max_depth': 36, 'learning_rate': 0.011731526168677498, 'n_estimators': 1862, 'min_child_samples': 74, 'subsample': 0.8163812825708675, 'colsample_bytree': 0.9351189365253362, 'reg_alpha': 0.0008526007072983226, 'reg_lambda': 0.02568828670087687}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:34:32,207] Trial 27 finished with value: 18.370484847691323 and parameters: {'num_leaves': 106, 'max_depth': 42, 'learning_rate': 0.0003582134778255171, 'n_estimators': 1563, 'min_child_samples': 94, 'subsample': 0.9418244367982378, 'colsample_bytree': 0.9155519259261179, 'reg_alpha': 0.04408305719421867, 'reg_lambda': 0.41247585718511803}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:36:06,494] Trial 28 finished with value: 16.965051953685705 and parameters: {'num_leaves': 79, 'max_depth': 23, 'learning_rate': 0.0022979991952884666, 'n_estimators': 1962, 'min_child_samples': 93, 'subsample': 0.8828862486527914, 'colsample_bytree': 0.8167151585869286, 'reg_alpha': 0.00012670400647970035, 'reg_lambda': 0.0002635765747879194}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:37:20,795] Trial 29 finished with value: 16.710598512925056 and parameters: {'num_leaves': 68, 'max_depth': 28, 'learning_rate': 0.006616495629157925, 'n_estimators': 1784, 'min_child_samples': 77, 'subsample': 0.928826495367574, 'colsample_bytree': 0.9823164102735746, 'reg_alpha': 0.0010858623703572628, 'reg_lambda': 0.001164714873992846}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:39:10,972] Trial 30 finished with value: 16.73186143376849 and parameters: {'num_leaves': 127, 'max_depth': 34, 'learning_rate': 0.01443473447380556, 'n_estimators': 1543, 'min_child_samples': 61, 'subsample': 0.7588621159847928, 'colsample_bytree': 0.8589995222406559, 'reg_alpha': 9.938312443209135e-05, 'reg_lambda': 0.13649695050330224}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:40:06,469] Trial 31 finished with value: 16.72858749064772 and parameters: {'num_leaves': 51, 'max_depth': 28, 'learning_rate': 0.024732506924480976, 'n_estimators': 1826, 'min_child_samples': 96, 'subsample': 0.8476565816091094, 'colsample_bytree': 0.7303368186455921, 'reg_alpha': 9.907098909625709e-06, 'reg_lambda': 2.036702351231284}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:40:56,816] Trial 32 finished with value: 16.94082771113287 and parameters: {'num_leaves': 50, 'max_depth': 41, 'learning_rate': 0.04494330338451064, 'n_estimators': 1714, 'min_child_samples': 90, 'subsample': 0.8675464494428062, 'colsample_bytree': 0.8000717312934431, 'reg_alpha': 0.0016717217951450385, 'reg_lambda': 0.014102457385204489}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:41:55,798] Trial 33 finished with value: 16.791228950711346 and parameters: {'num_leaves': 68, 'max_depth': 21, 'learning_rate': 0.005353873148008798, 'n_estimators': 1397, 'min_child_samples': 79, 'subsample': 0.8231684563588038, 'colsample_bytree': 0.8967721826681149, 'reg_alpha': 0.01451357467861589, 'reg_lambda': 0.9798021267368725}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:42:22,375] Trial 34 finished with value: 17.048896873025715 and parameters: {'num_leaves': 35, 'max_depth': 31, 'learning_rate': 0.09256987852804652, 'n_estimators': 1242, 'min_child_samples': 88, 'subsample': 0.8343840400954077, 'colsample_bytree': 0.8477905711134025, 'reg_alpha': 2.28120267494011e-06, 'reg_lambda': 0.2147464271857429}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:43:04,303] Trial 35 finished with value: 16.720939810313183 and parameters: {'num_leaves': 83, 'max_depth': 39, 'learning_rate': 0.022730571006991395, 'n_estimators': 863, 'min_child_samples': 31, 'subsample': 0.9749095044890217, 'colsample_bytree': 0.9584552495570552, 'reg_alpha': 1.4583323095911534e-05, 'reg_lambda': 6.611655924620725e-05}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:44:57,732] Trial 36 finished with value: 16.649937657533002 and parameters: {'num_leaves': 96, 'max_depth': 26, 'learning_rate': 0.008122557390903857, 'n_estimators': 1996, 'min_child_samples': 84, 'subsample': 0.7650046426152997, 'colsample_bytree': 0.664665604180857, 'reg_alpha': 9.976130860544096e-05, 'reg_lambda': 8.649093803490791}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:46:54,688] Trial 37 finished with value: 18.88780507276377 and parameters: {'num_leaves': 97, 'max_depth': 27, 'learning_rate': 0.0001040448491195485, 'n_estimators': 1996, 'min_child_samples': 82, 'subsample': 0.7493371721264949, 'colsample_bytree': 0.7785839423088876, 'reg_alpha': 7.04321609339336e-05, 'reg_lambda': 0.001149768525621673}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:48:45,851] Trial 38 finished with value: 16.66267836692751 and parameters: {'num_leaves': 117, 'max_depth': 35, 'learning_rate': 0.008509328496065838, 'n_estimators': 1654, 'min_child_samples': 99, 'subsample': 0.7846002488444322, 'colsample_bytree': 0.7322290986686419, 'reg_alpha': 0.00027822092268473583, 'reg_lambda': 0.07286513852526971}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:50:44,809] Trial 39 finished with value: 16.722317328617827 and parameters: {'num_leaves': 123, 'max_depth': 35, 'learning_rate': 0.004467871351751401, 'n_estimators': 1680, 'min_child_samples': 98, 'subsample': 0.698109372670939, 'colsample_bytree': 0.7006703166996694, 'reg_alpha': 0.012402220274124177, 'reg_lambda': 0.6510982150958421}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:52:38,588] Trial 40 finished with value: 16.647972543743226 and parameters: {'num_leaves': 103, 'max_depth': 46, 'learning_rate': 0.007170797587391718, 'n_estimators': 1902, 'min_child_samples': 85, 'subsample': 0.7751511862554397, 'colsample_bytree': 0.731762996327352, 'reg_alpha': 0.0027531351973803303, 'reg_lambda': 3.510463492915042e-05}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:54:45,300] Trial 41 finished with value: 16.661937479111213 and parameters: {'num_leaves': 117, 'max_depth': 50, 'learning_rate': 0.0072609502905758225, 'n_estimators': 1884, 'min_child_samples': 87, 'subsample': 0.7624423693888286, 'colsample_bytree': 0.7411447608407933, 'reg_alpha': 0.00048074320489786, 'reg_lambda': 3.731907714897466e-05}. Best is trial 20 with value: 16.645564336517356.\n",
      "[I 2025-01-12 10:56:39,809] Trial 42 finished with value: 16.75376311753672 and parameters: {'num_leaves': 103, 'max_depth': 50, 'learning_rate': 0.003671997600664983, 'n_estimators': 1886, 'min_child_samples': 84, 'subsample': 0.735727168669927, 'colsample_bytree': 0.7433924295435795, 'reg_alpha': 0.002294954382542137, 'reg_lambda': 3.535226411385486e-05}. Best is trial 20 with value: 16.645564336517356.\n",
      "[W 2025-01-12 10:57:33,238] Trial 43 failed with parameters: {'num_leaves': 114, 'max_depth': 47, 'learning_rate': 0.0018603411167223056, 'n_estimators': 1916, 'min_child_samples': 90, 'subsample': 0.6701460372477488, 'colsample_bytree': 0.6490759972914102, 'reg_alpha': 0.0007725802978763134, 'reg_lambda': 1.2213305240590361e-06} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cris/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/yl/0x3dd7c54t1_c1v97db4kly40000gn/T/ipykernel_13549/3684283419.py\", line 26, in objective\n",
      "    cv_score = cross_validate_efs_time(model, X, efs_time, cv=5)\n",
      "  File \"/var/folders/yl/0x3dd7c54t1_c1v97db4kly40000gn/T/ipykernel_13549/578855711.py\", line 20, in cross_validate_efs_time\n",
      "    model_copy.fit(X_train, y_train)\n",
      "  File \"/Users/cris/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1189, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cris/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 955, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/cris/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/lightgbm/engine.py\", line 307, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"/Users/cris/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/lightgbm/basic.py\", line 4136, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-12 10:57:33,242] Trial 43 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m reg_lambda \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;241m10.0\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMRegressor(\n\u001b[1;32m     13\u001b[0m     num_leaves\u001b[38;5;241m=\u001b[39mnum_leaves,\n\u001b[1;32m     14\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m cv_score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_efs_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mefs_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_score\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mcross_validate_efs_time\u001b[0;34m(model, X, efs_time, cv, scale)\u001b[0m\n\u001b[1;32m     16\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     18\u001b[0m model_copy \u001b[38;5;241m=\u001b[39m clone(model)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel_copy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_copy\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     23\u001b[0m cv_scores\u001b[38;5;241m.\u001b[39mappend(mean_absolute_error(y_test, y_pred))\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/lightgbm/sklearn.py:1189\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1174\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/lightgbm/sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/lightgbm/engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    296\u001b[0m     cb(\n\u001b[1;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/post-hct-survival-prediction/pyenv3-10/lib/python3.10/site-packages/lightgbm/basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4135\u001b[0m _safe_call(\n\u001b[0;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4140\u001b[0m )\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
